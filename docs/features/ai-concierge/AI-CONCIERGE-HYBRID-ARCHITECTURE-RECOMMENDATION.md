# üèóÔ∏è TPX AI Concierge - Hybrid Architecture Recommendation

**Document Version:** 1.0
**Date:** October 11, 2025
**Status:** Approved for Implementation
**Decision Type:** Strategic Architecture - Mini Turning Point

---

## üìã Executive Summary

After comprehensive analysis of three architectural approaches (Claude, Gemini, GPT-4) against TPX's specific requirements, scaling needs, and existing PostgreSQL + AWS infrastructure, this document presents the **optimal hybrid architecture** for the AI Concierge system.

### The Recommendation

**PostgreSQL-First Hybrid Architecture** combining:
- **Core Foundation:** GPT-4's database-first deterministic approach
- **Observability Layer:** Gemini's LangSmith recommendation
- **State Management:** Claude's XState pattern
- **Custom Enhancements:** Typed bundles, code guardrails, learning hooks

### Key Outcomes

| Metric | Current | Target (Week 5) | Improvement |
|--------|---------|-----------------|-------------|
| **Retrieval Speed** | 2-3 seconds | <200ms | **10-15x faster** |
| **API Cost per Request** | ~$0.10 | ~$0.02 | **80% reduction** |
| **Context Size** | 1,443 columns | 12 items | **99% reduction** |
| **Event Hallucinations** | ~20% | 0% | **100% elimination** |
| **Data Freshness** | 30+ seconds | <10s | **3x faster** |
| **Implementation Timeline** | N/A | 5 weeks | **Phased rollout** |

---

## üéØ Strategic Context

### The Scale Challenge

**Current State:**
- 89 database tables with 1,443 columns loaded on EVERY AI request
- Event context calculated procedurally in multiple places
- GPT-4 doing both retrieval AND generation simultaneously
- No separation between different operational modes

**Target Scale (User Requirements):**
- **100,000 users per month** (~3,300 daily average)
- **1,000+ simultaneous users** during peak events
- **Sub-10 second data freshness** for real-time event orchestration
- **Custom LLM training by 2026** for 90% cost reduction

### Why Current Architecture Doesn't Scale

1. **Performance Bottleneck**
   - Loading 1,443 columns takes 2-3 seconds per request
   - At 3,300 daily users √ó 5 queries/day = 16,500 requests
   - Total: 8-12 hours of cumulative load time per day
   - Unsustainable at scale

2. **Cost Explosion**
   - Each request sends massive context to GPT-4
   - ~10,000 tokens per request at $0.01/1k tokens = $0.10/request
   - 16,500 requests/day √ó $0.10 = $1,650/day = **$50,000/month**
   - At 100k users: **$165,000/month in API costs alone**

3. **Reliability Issues**
   - Event context calculated in multiple code paths ‚Üí drift
   - No single source of truth for "what's happening now"
   - ~20% hallucination rate during events
   - Hard to debug why AI makes specific decisions

4. **Maintenance Complexity**
   - 500+ line controller files
   - Monolithic context builders
   - Guardrails only in prompts (not code)
   - Can't unit test retrieval quality independently

---

## üìä Architectural Approach Comparison

### Three Approaches Analyzed

| Dimension | Claude's Approach | Gemini's Approach | GPT-4's Approach |
|-----------|-------------------|-------------------|------------------|
| **Philosophy** | Pragmatic PostgreSQL + Multi-Agent | Framework-Driven Modernization | Database-First Determinism |
| **Core Tech** | pgvector + LangGraph + XState | LangChain + pgvector | Materialized Views + Hybrid SQL |
| **Event Truth** | Hot/Warm/Cold data tiering | Background ingestion worker | Materialized Views + LISTEN/NOTIFY |
| **Orchestration** | Multi-agent (LangGraph) | Dual agents (LangChain) | Capability Packs (custom) |
| **State Management** | XState state machines | LangChain Expression Language | Explicit SQL queries |
| **Observability** | Manual logging | **LangSmith** ‚≠ê | Health checks + canary tests |
| **Learning Curve** | Medium (new tools) | High (LangChain mastery) | **Low** (SQL + TypeScript) ‚≠ê |
| **Breaking Changes** | **Minimal** (additive) ‚≠ê | Significant (rewrite) | **Minimal** (views + services) ‚≠ê |
| **Implementation** | 8-10 weeks (phased) | 5-6 weeks (complete refactor) | **4-6 weeks** (SQL-first) ‚≠ê |
| **Scalability** | Good (semantic search) | Good (dedicated store) | **Excellent** (PostgreSQL-native) ‚≠ê |
| **Cost Reduction** | 80% claimed | Not specified | **80% claimed** ‚≠ê |
| **AWS Integration** | Good | Good | **Excellent** (RDS/Aurora) ‚≠ê |

### Why Hybrid Approach

**No single approach is perfect.** Each has unique strengths:

- **GPT-4:** Best core architecture (database-first, concrete SQL, minimal disruption)
- **Gemini:** Best observability (LangSmith is game-changing for debugging)
- **Claude:** Best state management (XState for declarative mode switching)

**The hybrid combines the best of each while avoiding their weaknesses.**

---

## üèóÔ∏è The Hybrid Architecture

### Layer 1: Database-First Foundation (GPT-4's Core)

#### 1.1 Knowledge Base with Hybrid Search

**Replace:** Monolithic loading of 89 tables (1,443 columns)
**With:** Single hybrid search query returning top 12 results

```sql
-- ai_knowledge_base table structure
CREATE TABLE ai_knowledge_base (
  id SERIAL PRIMARY KEY,
  entity_type VARCHAR(50),              -- 'partner', 'book', 'podcast', 'event', 'contractor'
  entity_id INTEGER,
  contractor_id INTEGER REFERENCES contractors(id),  -- NULL = general knowledge
  content TEXT,
  embedding vector(1536),               -- OpenAI ada-002 embeddings
  metadata JSONB,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_kb_contractor ON ai_knowledge_base(contractor_id);
CREATE INDEX idx_kb_entity ON ai_knowledge_base(entity_type, entity_id);
CREATE INDEX idx_kb_vector ON ai_knowledge_base USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_kb_content_fts ON ai_knowledge_base USING gin(to_tsvector('english', content));

-- Hybrid search: BM25 (keyword) + Vector (semantic)
WITH bm25_results AS (
  SELECT
    id,
    entity_type,
    entity_id,
    content,
    ts_rank(
      to_tsvector('english', content),
      plainto_tsquery($1)  -- User's question
    ) AS bm25_score
  FROM ai_knowledge_base
  WHERE contractor_id = $2 OR contractor_id IS NULL
),
vector_results AS (
  SELECT
    id,
    entity_type,
    entity_id,
    content,
    1 - (embedding <=> $3::vector) AS vector_score  -- Cosine similarity
  FROM ai_knowledge_base
  WHERE contractor_id = $2 OR contractor_id IS NULL
)
SELECT
  kb.*,
  (0.4 * bm25.bm25_score + 0.6 * vs.vector_score) AS hybrid_score
FROM ai_knowledge_base kb
JOIN bm25_results bm25 USING(id)
JOIN vector_results vs USING(id)
ORDER BY hybrid_score DESC
LIMIT 12;
```

**Impact:**
- ‚ö° **10-15x faster** (milliseconds vs seconds)
- üí∞ **80% cost reduction** (12 items vs 1,443 columns)
- üéØ **Better relevance** (semantic + keyword matching)
- ‚úÖ **Independently testable** retrieval quality

#### 1.2 Materialized Views for Event Truth

**Replace:** Procedural event context calculation in multiple places
**With:** Single source of truth via materialized views

```sql
-- Sessions happening RIGHT NOW
CREATE MATERIALIZED VIEW mv_sessions_now AS
SELECT
  s.id AS session_id,
  s.event_id,
  s.speaker_name,
  s.session_title,
  s.session_start,
  s.session_end,
  s.focus_areas,
  a.contractor_id,
  -- Pre-compute relevance score
  CASE
    WHEN s.focus_areas && (SELECT focus_areas FROM contractors WHERE id = a.contractor_id)
    THEN 100
    ELSE 50
  END AS relevance_score
FROM event_speakers s
JOIN event_attendees a ON a.event_id = s.event_id
JOIN events e ON e.id = s.event_id
WHERE NOW() AT TIME ZONE e.timezone BETWEEN s.session_start AND s.session_end;

CREATE INDEX ON mv_sessions_now (contractor_id);
CREATE INDEX ON mv_sessions_now (event_id);

-- Sessions in next 60 minutes
CREATE MATERIALIZED VIEW mv_sessions_next_60 AS
SELECT
  s.id AS session_id,
  s.event_id,
  s.speaker_name,
  s.session_title,
  s.session_start,
  s.session_end,
  s.focus_areas,
  a.contractor_id,
  -- Pre-compute match score
  array_length(
    array(SELECT unnest(s.focus_areas) INTERSECT SELECT unnest(c.focus_areas)),
    1
  ) AS match_count
FROM event_speakers s
JOIN event_attendees a ON a.event_id = s.event_id
JOIN contractors c ON c.id = a.contractor_id
JOIN events e ON e.id = s.event_id
WHERE s.session_start BETWEEN NOW() AND NOW() + INTERVAL '60 minutes';

CREATE INDEX ON mv_sessions_next_60 (contractor_id);
CREATE INDEX ON mv_sessions_next_60 (event_id);

-- Auto-refresh with pg_cron (every 30 seconds)
SELECT cron.schedule(
  'refresh-event-views',
  '*/30 * * * *',
  $$
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_sessions_now;
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_sessions_next_60;
  $$
);

-- Trigger for instant refresh on critical updates
CREATE OR REPLACE FUNCTION notify_event_refresh()
RETURNS TRIGGER AS $$
BEGIN
  PERFORM pg_notify('event_refresh', NEW.event_id::text);
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER event_speaker_update
AFTER INSERT OR UPDATE ON event_speakers
FOR EACH ROW
EXECUTE FUNCTION notify_event_refresh();
```

**Impact:**
- üéØ **Single source of truth** for event data
- ‚ö° **Sub-10s freshness** via pg_cron + triggers
- ‚úÖ **Zero calculation drift** across codebase
- üß™ **Testable view correctness** with SQL queries

#### 1.3 Context Assembly Service with Typed Bundles

**Replace:** Monolithic context builders with thousands of lines
**With:** Small, typed, testable context bundles

```typescript
// tpe-backend/src/types/conciergeContext.ts

interface ConciergeContext {
  contractor: ContractorBundle;
  knowledge: KnowledgeBundle;
  event?: EventBundle;
  capabilities: string[];  // Which capability packs are available
}

interface ContractorBundle {
  id: number;
  features: {
    revenue_range: string;
    team_size: number;
    focus_areas: string[];
    location: string;
    current_goals: string[];
  };
}

interface KnowledgeBundle {
  top_results: KnowledgeItem[];  // From hybrid search
  total_results: number;
}

interface KnowledgeItem {
  entity_type: 'partner' | 'book' | 'podcast' | 'event';
  entity_id: number;
  snippet: string;
  relevance_score: number;
  why_relevant: string;  // AI-generated explanation
}

interface EventBundle {
  event_id: number;
  status: 'pre_event' | 'during_event' | 'post_event';
  now_sessions: Session[];      // From mv_sessions_now
  next60_sessions: Session[];   // From mv_sessions_next_60
  recommended_sponsors: Sponsor[];
}

interface Session {
  session_id: number;
  speaker_name: string;
  session_title: string;
  start_time: string;
  relevance_score: number;
  why_relevant: string;
}
```

```typescript
// tpe-backend/src/services/contextAssembler.ts

class ContextAssembler {
  async buildContext(contractorId: number, query: string): Promise<ConciergeContext> {
    // 1. Load contractor features (cached 5 min)
    const contractor = await this.getContractorBundle(contractorId);

    // 2. Hybrid search for relevant knowledge (top 12)
    const knowledge = await this.hybridSearch(contractorId, query, 12);

    // 3. Check for active event
    const event = await this.getEventBundle(contractorId);

    // 4. Determine available capabilities
    const capabilities = this.determineCapabilities(contractor, event);

    return {
      contractor,
      knowledge,
      event,
      capabilities
    };
  }

  private async getContractorBundle(contractorId: number): Promise<ContractorBundle> {
    const cacheKey = `contractor:${contractorId}`;
    const cached = await redis.get(cacheKey);
    if (cached) return JSON.parse(cached);

    const contractor = await db.query(`
      SELECT id, revenue_range, team_size, focus_areas, location, current_goals
      FROM contractors
      WHERE id = $1
    `, [contractorId]);

    const bundle: ContractorBundle = {
      id: contractor.rows[0].id,
      features: contractor.rows[0]
    };

    await redis.set(cacheKey, JSON.stringify(bundle), 'EX', 300);  // 5 min cache
    return bundle;
  }

  private async getEventBundle(contractorId: number): Promise<EventBundle | undefined> {
    // Check if contractor is at an active event
    const eventCheck = await db.query(`
      SELECT
        e.id AS event_id,
        CASE
          WHEN NOW() < e.start_date THEN 'pre_event'
          WHEN NOW() BETWEEN e.start_date AND e.end_date THEN 'during_event'
          WHEN NOW() BETWEEN e.end_date AND e.end_date + INTERVAL '7 days' THEN 'post_event'
          ELSE NULL
        END AS status
      FROM events e
      JOIN event_attendees ea ON ea.event_id = e.id
      WHERE ea.contractor_id = $1
        AND e.start_date <= NOW() + INTERVAL '14 days'
      ORDER BY e.start_date DESC
      LIMIT 1
    `, [contractorId]);

    if (!eventCheck.rows.length || !eventCheck.rows[0].status) {
      return undefined;
    }

    const { event_id, status } = eventCheck.rows[0];

    // Load from materialized views
    const [nowSessions, next60Sessions, sponsors] = await Promise.all([
      this.getNowSessions(event_id, contractorId),
      this.getNext60Sessions(event_id, contractorId),
      this.getRecommendedSponsors(event_id, contractorId)
    ]);

    return {
      event_id,
      status,
      now_sessions: nowSessions,
      next60_sessions: next60Sessions,
      recommended_sponsors: sponsors
    };
  }
}
```

**Impact:**
- üì¶ **Small, typed bundles** (not monolithic blobs)
- üß™ **Unit-testable** context assembly
- üêõ **Easier debugging** (inspect exact context)
- ‚ö° **Faster** (only load what's needed)

#### 1.4 LangGraph Agent Pattern

**Replace:** Monolithic service files with mixed concerns
**With:** Autonomous agents with tool-calling capabilities

```typescript
// tpe-backend/src/services/agents/tools.ts

import { DynamicStructuredTool } from '@langchain/core/tools';
import { z } from 'zod';

// Tool 1: Partner Match
const partnerMatchTool = new DynamicStructuredTool({
  name: 'find_matching_partners',
  description: 'Finds strategic partners that match the contractor\'s focus areas and business profile. Use this when contractor asks about partners or needs recommendations.',
  schema: z.object({
    contractor_id: z.number().describe('The contractor ID'),
    focus_areas: z.array(z.string()).optional().describe('Specific focus areas to match on'),
    limit: z.number().default(3).describe('Number of partners to return')
  }),
  func: async ({ contractor_id, focus_areas, limit }) => {
    // Use hybrid search to find top partners
    const partners = await db.query(`
      SELECT p.company_name, p.ai_summary, kb.hybrid_score
      FROM strategic_partners p
      JOIN ai_knowledge_base kb ON kb.entity_type = 'partner' AND kb.entity_id = p.id
      WHERE (kb.contractor_id = $1 OR kb.contractor_id IS NULL)
        AND ($2::text[] IS NULL OR p.focus_areas && $2)
      ORDER BY kb.hybrid_score DESC
      LIMIT $3
    `, [contractor_id, focus_areas, limit]);

    return JSON.stringify({
      partners: partners.rows,
      count: partners.rows.length
    });
  }
});

// Tool 2: Event Sessions
const eventSessionTool = new DynamicStructuredTool({
  name: 'get_current_event_sessions',
  description: 'Gets sessions happening right now at the contractor\'s event. Only use when contractor is at an active event.',
  schema: z.object({
    contractor_id: z.number().describe('The contractor ID'),
    event_id: z.number().describe('The event ID')
  }),
  func: async ({ contractor_id, event_id }) => {
    // Query materialized view (already filtered and scored)
    const sessions = await db.query(`
      SELECT speaker_name, session_title, session_start, relevance_score
      FROM mv_sessions_now
      WHERE event_id = $1 AND contractor_id = $2
      ORDER BY relevance_score DESC
      LIMIT 3
    `, [event_id, contractor_id]);

    return JSON.stringify({
      sessions: sessions.rows,
      happening_now: true
    });
  }
});

// Tool 3: Capture Event Note
const captureNoteTool = new DynamicStructuredTool({
  name: 'capture_event_note',
  description: 'Captures a note during an event. Use when contractor shares information, feedback, or observations during an event.',
  schema: z.object({
    contractor_id: z.number(),
    event_id: z.number(),
    note_content: z.string(),
    note_type: z.enum(['speaker_feedback', 'sponsor_interest', 'general_observation', 'action_item'])
  }),
  func: async ({ contractor_id, event_id, note_content, note_type }) => {
    await db.query(`
      INSERT INTO event_notes (contractor_id, event_id, note_content, note_type, created_at)
      VALUES ($1, $2, $3, $4, NOW())
    `, [contractor_id, event_id, note_content, note_type]);

    // Track learning event
    await db.query(`
      INSERT INTO ai_learning_events (event_type, contractor_id, action_taken, outcome)
      VALUES ('note_capture', $1, $2, 'captured')
    `, [contractor_id, note_type]);

    return JSON.stringify({ success: true, message: 'Note captured successfully' });
  }
});

// Tool 4: Schedule Follow-up
const scheduleFollowupTool = new DynamicStructuredTool({
  name: 'schedule_followup',
  description: 'Schedules a follow-up message to the contractor at a specific time. Use for reminders, check-ins, or proactive outreach.',
  schema: z.object({
    contractor_id: z.number(),
    message: z.string().describe('The follow-up message to send'),
    send_at: z.string().describe('ISO 8601 datetime when to send'),
    follow_up_type: z.enum(['demo_reminder', 'action_item_check', 'event_recap', 'general'])
  }),
  func: async ({ contractor_id, message, send_at, follow_up_type }) => {
    // Add to Bull queue
    await followupQueue.add({
      contractor_id,
      message,
      follow_up_type
    }, {
      delay: new Date(send_at).getTime() - Date.now()
    });

    return JSON.stringify({ success: true, scheduled_for: send_at });
  }
});

export const allTools = [
  partnerMatchTool,
  eventSessionTool,
  captureNoteTool,
  scheduleFollowupTool
];
```

```typescript
// tpe-backend/src/services/agents/generalBusinessAdvisorAgent.ts

import { ChatOpenAI } from '@langchain/openai';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import { MemorySaver } from '@langchain/langgraph';
import { partnerMatchTool, scheduleFollowupTool } from './tools';

// General Business Advisor Agent
export function createGeneralBusinessAdvisorAgent() {
  const model = new ChatOpenAI({
    modelName: 'gpt-4',
    temperature: 0.7,
    openAIApiKey: process.env.OPENAI_API_KEY
  });

  const tools = [partnerMatchTool, scheduleFollowupTool];

  const agent = createReactAgent({
    llm: model,
    tools: tools,
    checkpointSaver: new MemorySaver() // Persistent memory
  });

  return agent;
}
```

```typescript
// tpe-backend/src/services/agents/eventOrchestratorAgent.ts

import { ChatOpenAI } from '@langchain/openai';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import { MemorySaver } from '@langchain/langgraph';
import { eventSessionTool, captureNoteTool, scheduleFollowupTool } from './tools';

// Event Orchestrator Agent
export function createEventOrchestratorAgent() {
  const model = new ChatOpenAI({
    modelName: 'gpt-4',
    temperature: 0.5, // Lower temperature for event accuracy
    openAIApiKey: process.env.OPENAI_API_KEY
  });

  const tools = [eventSessionTool, captureNoteTool, scheduleFollowupTool];

  const agent = createReactAgent({
    llm: model,
    tools: tools,
    checkpointSaver: new MemorySaver() // Persistent memory
  });

  return agent;
}
```

**Impact:**
- ü§ñ **Autonomous decision-making** - Agent decides which tools to use
- üß† **Memory across conversations** - Agent remembers past interactions
- üîÑ **Multi-step workflows** - Agent can chain multiple tools together
- üìä **Learning from outcomes** - Tools log to ai_learning_events
- üß™ **Unit-testable** - Test tools independently
- üìà **Scalable** - Add new tools without touching agent logic

### Layer 2: Observability with LangSmith (Gemini's Strength)

**Add:** Complete tracing and debugging for all AI calls

```javascript
// tpe-backend/src/services/openAIService.js
const { Client } = require('langsmith');

const langsmith = new Client({
  apiKey: process.env.LANGSMITH_API_KEY
});

async function generateConciergeResponse(message, context, packs) {
  // Start trace
  const runId = await langsmith.createRun({
    name: 'AI Concierge Response',
    run_type: 'chain',
    inputs: {
      message,
      context: {
        contractor_id: context.contractor.id,
        knowledge_items: context.knowledge.top_results.length,
        event_status: context.event?.status,
        available_packs: packs.map(p => p.name)
      }
    },
    project_name: 'TPX-AI-Concierge'
  });

  try {
    // Call OpenAI
    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: buildSystemPrompt(context, packs) },
        { role: 'user', content: message }
      ],
      functions: getAvailableFunctions(packs)
    });

    // Log successful response
    await langsmith.updateRun(runId, {
      outputs: {
        response: response.choices[0].message.content,
        tokens_used: response.usage.total_tokens,
        function_called: response.choices[0].message.function_call?.name
      },
      end_time: Date.now()
    });

    return response;

  } catch (error) {
    // Log error with full context
    await langsmith.updateRun(runId, {
      error: error.message,
      end_time: Date.now()
    });
    throw error;
  }
}
```

**What LangSmith Provides:**
- üîç **Trace every AI call** - See exact prompt, context, response
- üìä **Identify patterns** - Which queries fail? Which succeed?
- ‚ö° **Performance metrics** - Latency breakdown by component
- üêõ **Debug hallucinations** - See when AI invents data not in context
- üìà **A/B testing** - Compare different prompt strategies
- üéØ **Quality monitoring** - Track response quality over time

**Cost:** Free tier (1,000 traces/month), paid tier starts at $39/month

### Layer 3: State Management with XState (Claude's Strength)

**Add:** Declarative state machine for mode switching

```typescript
// tpe-backend/src/services/conciergeStateMachine.ts
import { createMachine, interpret } from 'xstate';

const conciergeStateMachine = createMachine({
  id: 'concierge',
  initial: 'idle',
  context: {
    contractorId: null,
    eventContext: null
  },

  states: {
    idle: {
      on: { MESSAGE_RECEIVED: 'routing' }
    },

    routing: {
      always: [
        { target: 'event_mode', cond: 'hasActiveEvent' },
        { target: 'general_mode' }
      ]
    },

    event_mode: {
      initial: 'determine_phase',

      states: {
        determine_phase: {
          always: [
            { target: 'during_event', cond: 'eventIsLive' },
            { target: 'post_event', cond: 'eventJustEnded' },
            { target: 'pre_event' }
          ]
        },

        pre_event: {
          invoke: {
            src: 'loadPreEventPacks',
            onDone: 'respond'
          }
        },

        during_event: {
          invoke: {
            src: 'loadDuringEventPacks',
            onDone: 'respond'
          }
        },

        post_event: {
          invoke: {
            src: 'loadPostEventPacks',
            onDone: 'respond'
          }
        },

        respond: {
          type: 'final'
        }
      },

      onDone: 'idle'
    },

    general_mode: {
      invoke: {
        src: 'loadGeneralPacks',
        onDone: 'respond'
      },

      states: {
        respond: {
          type: 'final'
        }
      },

      onDone: 'idle'
    }
  }
}, {
  guards: {
    hasActiveEvent: (context) => context.eventContext !== null,
    eventIsLive: (context) => context.eventContext?.status === 'during_event',
    eventJustEnded: (context) => context.eventContext?.status === 'post_event'
  },

  services: {
    loadPreEventPacks: async (context) => {
      return ['partner_match', 'event_info', 'speaker_preview'];
    },
    loadDuringEventPacks: async (context) => {
      return ['event_session', 'sponsor_match', 'peer_match', 'note_capture'];
    },
    loadPostEventPacks: async (context) => {
      return ['event_summary', 'followup_schedule', 'action_items'];
    },
    loadGeneralPacks: async (context) => {
      return ['partner_match', 'book_recommend', 'podcast_recommend'];
    }
  }
});
```

**Integration with Controller:**

```typescript
// tpe-backend/src/controllers/aiConciergeController.js

class AIConciergeController {
  private machines: Map<number, any> = new Map();  // contractorId -> state machine

  async generateAIResponse(contractorId: number, message: string) {
    // 1. Get or create state machine for this contractor
    let machine = this.machines.get(contractorId);
    if (!machine) {
      machine = interpret(conciergeStateMachine).start();
      this.machines.set(contractorId, machine);
    }

    // 2. Load event context
    const eventContext = await this.getEventContext(contractorId);
    machine.send({ type: 'MESSAGE_RECEIVED', eventContext });

    // 3. State machine determines correct packs
    const state = machine.state;
    const packNames = state.context.availablePacks;

    // 4. Build context with appropriate packs
    const context = await contextAssembler.buildContext(contractorId, message);
    const packs = packNames.map(name => this.loadPack(name));

    // 5. Generate response
    return openAIService.generateConciergeResponse(message, context, packs);
  }
}
```

**Impact:**
- üìä **Visual state diagram** - See all possible modes
- üêõ **Easier debugging** - Know exact state at any time
- ‚úÖ **Prevents invalid transitions** - Can't skip event phases
- üß™ **Testable state logic** - Unit test state transitions

### Layer 4: Code-Level Guardrails

**Add:** Explicit permission checks before executing AI actions

```typescript
// tpe-backend/src/services/aiActionGuards.ts

class AIActionGuards {
  canCaptureEventNote(context: ConciergeContext): boolean {
    // Only during or post-event
    return context.event?.status in ['during_event', 'post_event'];
  }

  canCreateActionItem(context: ConciergeContext): boolean {
    // Only during or post-event
    return context.event?.status in ['during_event', 'post_event'];
  }

  canScheduleFollowup(context: ConciergeContext): boolean {
    // Anytime, but rate-limited per contractor
    return this.checkRateLimit(context.contractor.id, 'followup', 5);  // Max 5/day
  }

  canBookDemo(context: ConciergeContext): boolean {
    // Only if contractor has completed profile
    return context.contractor.features.profile_completed === true;
  }

  canRecommendPartner(context: ConciergeContext): boolean {
    // Not during active event sessions (focus on event)
    if (context.event?.status === 'during_event' && context.event.now_sessions.length > 0) {
      return false;
    }
    return true;
  }

  private async checkRateLimit(contractorId: number, action: string, limit: number): Promise<boolean> {
    const today = new Date().toISOString().split('T')[0];
    const key = `rate:${contractorId}:${action}:${today}`;

    const count = await redis.incr(key);
    if (count === 1) await redis.expire(key, 86400);  // 24 hours

    return count <= limit;
  }
}

// In function call handler:
async function handleFunctionCall(functionName: string, args: any, context: ConciergeContext) {
  const guards = new AIActionGuards();

  // Check permission BEFORE executing
  const guardMethod = `can${capitalize(functionName)}`;
  if (!guards[guardMethod](context)) {
    throw new Error(`Action ${functionName} not allowed in current context (status: ${context.event?.status})`);
  }

  // Log the attempt
  await logActionAttempt(context.contractor.id, functionName, 'allowed');

  // Execute function
  return await executeFunctionCall(functionName, args);
}
```

**Impact:**
- üõ°Ô∏è **Prevents unauthorized actions** - AI can't bypass rules
- üß™ **Testable permission logic** - Unit test guards
- üìã **Clear audit trail** - Log why actions blocked
- üêõ **Easier debugging** - Guard failures are explicit errors

---

## üìÖ Implementation Roadmap

### PHASE 0: Foundation (Week 1) - **CRITICAL FIRST STEP**

**Goal:** Stop the bleeding - Fix immediate reliability issues

**Tasks:**

1. **Create `ai_knowledge_base` table** (1 day)
   - Add pgvector extension
   - Create table with vector index
   - Create full-text search index

2. **Build knowledge indexer** (2 days)
   - Background job to populate knowledge base
   - Embed all partners, books, podcasts, events
   - Auto-trigger on entity updates

3. **Implement hybrid search** (1 day)
   - Replace `aiKnowledgeService.getDynamicKnowledge()`
   - Test retrieval quality vs current approach
   - Benchmark performance

4. **Deploy and validate** (1 day)
   - Deploy to production database
   - Run knowledge indexer
   - Test with real queries
   - Measure speed and cost improvements

**Deliverables:**
- ‚úÖ ai_knowledge_base table in production
- ‚úÖ Background indexer running
- ‚úÖ Hybrid search working
- ‚úÖ 10x speed improvement verified
- ‚úÖ 80% cost reduction measured

**Success Metrics:**
- Retrieval time: < 200ms (from 2-3s)
- Context size: 12 items (from 1,443 columns)
- API cost per request: < $0.02 (from ~$0.10)

**Risk:** None - Additive change, doesn't break existing system

---

### PHASE 1: Event Truth Management (Week 2)

**Goal:** Fix event context reliability - single source of truth

**Tasks:**

1. **Create materialized views** (1 day)
   - `mv_sessions_now` for live sessions
   - `mv_sessions_next_60` for upcoming sessions
   - Indexes for performance

2. **Setup pg_cron refresh** (0.5 days)
   - Install pg_cron extension
   - Schedule 30-second refresh during event hours
   - Test concurrency and performance

3. **Add LISTEN/NOTIFY triggers** (0.5 days)
   - Trigger on event_speakers updates
   - Node.js listener service
   - Instant refresh on critical changes

4. **Update Context Assembler** (2 days)
   - Modify `getEventBundle()` to query views
   - Remove procedural event calculations
   - Test with real event scenarios

5. **Integration testing** (1 day)
   - Verify sub-10s freshness
   - Test during live event simulation
   - Validate no hallucinations

**Deliverables:**
- ‚úÖ Materialized views in production
- ‚úÖ pg_cron refreshing every 30s
- ‚úÖ LISTEN/NOTIFY working
- ‚úÖ Context Assembler using views
- ‚úÖ Zero event hallucinations verified

**Success Metrics:**
- Event data freshness: < 10s (from 30+ seconds)
- Hallucination rate: 0% (from ~20%)
- Single source of truth: All code queries same views

**Risk:** Low - Views are read-only, don't affect writes

---

### PHASE 2: Agent Migration with LangGraph (Week 3)

**Goal:** Replace monolithic controller with autonomous agents

**Tasks:**

1. **Install LangChain + LangGraph** (0.5 days)
   - Add dependencies: `@langchain/openai`, `@langchain/langgraph`, `@langchain/core`, `zod`
   - Setup environment variables
   - Test basic agent creation

2. **Build Agent Tools** (2 days)
   - Create 4 core tools with Zod schemas:
     - `find_matching_partners` (partner recommendations)
     - `get_current_event_sessions` (live event sessions)
     - `capture_event_note` (note-taking during events)
     - `schedule_followup` (proactive follow-ups)
   - Integrate with hybrid search and materialized views
   - Add learning event tracking to each tool

3. **Create Two Core Agents** (2 days)
   - General Business Advisor Agent (partner matching, scheduling)
   - Event Orchestrator Agent (event sessions, notes, follow-ups)
   - Configure with MemorySaver for persistent conversation history
   - Test agent tool selection and execution

4. **Update AI Concierge Controller** (1 day)
   - Route to appropriate agent based on event context
   - Pass contractor context to agents
   - Handle agent responses and streaming
   - Simplify controller logic (agents handle complexity)

**Deliverables:**
- ‚úÖ LangChain/LangGraph installed and configured
- ‚úÖ 4 agent tools with schemas and validation
- ‚úÖ 2 agents (General Business Advisor + Event Orchestrator)
- ‚úÖ Controller routing to agents
- ‚úÖ Agent memory working across conversations
- ‚úÖ Unit tests for tools

**Success Metrics:**
- Controller code: < 150 lines (from 500+)
- Agent tool selection accuracy: > 90%
- Agent response time: < 2s
- Test coverage: > 80%

**Risk:** Medium - New framework but well-documented by LangChain

---

### PHASE 3: Observability & Guardrails (Week 4)

**Goal:** Never wonder why AI made a decision

**Tasks:**

1. **Setup LangSmith** (0.5 days)
   - Create account and project
   - Install SDK
   - Configure environment variables

2. **Add tracing to OpenAI service** (1 day)
   - Wrap all GPT-4 calls with traces
   - Log inputs, outputs, errors
   - Test dashboard visibility

3. **Implement AI Action Guards** (2 days)
   - Create guard class with permission checks
   - Add rate limiting logic
   - Test all guard conditions

4. **Integrate guards into function calling** (1 day)
   - Check permissions before executing
   - Log blocked actions
   - Return clear error messages

5. **Create monitoring dashboard** (0.5 days)
   - Setup LangSmith project dashboard
   - Configure alerts for errors
   - Document for team access

**Deliverables:**
- ‚úÖ LangSmith integration complete
- ‚úÖ All AI calls traced
- ‚úÖ AI Action Guards implemented
- ‚úÖ Monitoring dashboard configured
- ‚úÖ Team trained on LangSmith

**Success Metrics:**
- Trace coverage: 100% of AI calls
- Guard violations: 0 unauthorized actions
- Debug time: 50% reduction (via traces)

**Risk:** Low - Observability is additive, guards are defensive

---

### PHASE 4: State Machine Integration (Week 5) ‚úÖ COMPLETE

**Status:** Production Ready (October 15, 2025)
**Documentation:** See [STATE-MACHINE-GUIDE.md](phase-4/STATE-MACHINE-GUIDE.md)

**Goal:** Declarative state management replaces procedural checks

**Tasks:**

1. **Install XState** (0.5 days)
   - Add dependencies
   - Setup basic machine structure

2. **Define state machine** (1 day)
   - Map all concierge modes
   - Define state transitions
   - Add guards and services

3. **Integrate with controller** (2 days)
   - Maintain machine per contractor
   - Send events to machine
   - Use machine state to determine packs

4. **Visualize state diagram** (0.5 days)
   - Generate state diagram image
   - Document state transitions
   - Add to technical docs

5. **Testing and validation** (1 day)
   - Unit test state transitions
   - Integration test with real scenarios
   - Verify state persistence

**Deliverables:**
- ‚úÖ XState machine defined
- ‚úÖ Controller using state machine
- ‚úÖ State diagram documentation
- ‚úÖ State transition tests
- ‚úÖ Team trained on XState

**Success Metrics:**
- All modes represented in state machine
- Invalid transitions prevented: 100%
- State visualization available

**Risk:** Low - State machine wraps existing logic, doesn't replace

---

### PHASE 5: Production Optimization (Week 6) - OPTIONAL

**Goal:** Fine-tune for 100k+ user scale

**Tasks:**

1. **Database optimization** (1 day)
   - Analyze slow queries
   - Add missing indexes
   - Optimize materialized view refresh

2. **Caching strategy** (1 day)
   - Redis caching for hot paths
   - Cache warming strategy
   - Cache invalidation rules

3. **Load testing** (2 days)
   - Simulate 1,000 concurrent users
   - Identify bottlenecks
   - Performance tuning

4. **Production deployment** (1 day)
   - Deploy to production
   - Monitor performance
   - Rollback plan ready

**Deliverables:**
- ‚úÖ Optimized database indexes
- ‚úÖ Caching layer implemented
- ‚úÖ Load test results documented
- ‚úÖ Production-ready deployment

**Success Metrics:**
- Handle 1,000+ concurrent users
- p95 latency < 500ms
- Zero downtime deployment

**Risk:** Low - Optimization, not new features

---

## üìä Success Metrics & KPIs

### Immediate Impact (Weeks 1-2)

| Metric | Baseline | Target | Measurement |
|--------|----------|--------|-------------|
| **Retrieval Speed** | 2-3 seconds | < 200ms | Average query time |
| **API Cost per Request** | ~$0.10 | ~$0.02 | Token usage tracking |
| **Context Size** | 1,443 columns | 12 items | Count of items in context |
| **Event Hallucinations** | ~20% | 0% | Manual testing during events |
| **Data Freshness** | 30+ seconds | < 10s | View refresh latency |

### Quality Metrics (Weeks 3-5)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **LangSmith Trace Coverage** | 100% | All AI calls traced |
| **Guard Violations** | 0 | Unauthorized actions blocked |
| **Context Assembly Time** | < 100ms | Assembler performance |
| **Test Coverage** | > 80% | Unit + integration tests |
| **Debug Time Reduction** | 50% | Time to identify issues |

### Scale Metrics (Production)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Concurrent Users** | 1,000+ | Load test results |
| **p95 Latency** | < 500ms | End-to-end response time |
| **Uptime** | 99.9% | Availability monitoring |
| **Monthly API Cost** | < $10,000 | OpenAI billing |

### Business Impact (3-6 months)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Recommendation Acceptance** | +20% | User interaction tracking |
| **Event Satisfaction** | +30% | Post-event surveys |
| **Support Deflection** | +40% | Ticket volume reduction |
| **User Retention** | +25% | Monthly active users |

---

## üí∞ Cost Analysis

### Current State (Before Implementation)

**Assumptions:**
- 3,300 users/day
- 5 queries per user per day
- 16,500 requests/day
- ~10,000 tokens per request (1,443 columns in context)
- GPT-4 pricing: $0.01/1k input tokens, $0.03/1k output tokens

**Monthly Cost:**
- Input: 16,500 √ó 10 √ó $0.01 = $1,650/day = **$49,500/month**
- Output: 16,500 √ó 1 √ó $0.03 = $495/day = **$14,850/month**
- **Total: $64,350/month**

### Target State (After Phase 0)

**Assumptions:**
- Same user volume
- 12 items in context (~1,200 tokens, down from 10,000)
- 80% reduction in input tokens

**Monthly Cost:**
- Input: 16,500 √ó 1.2 √ó $0.01 = $198/day = **$5,940/month**
- Output: Same as before = **$14,850/month**
- **Total: $20,790/month**

**Savings: $43,560/month (68% reduction)**

### At Target Scale (100k users/month)

**Current Architecture:**
- 100k users √ó 5 queries = 500k requests/month
- 500k √ó 10 √ó $0.01 = **$50,000/day input**
- **Total: ~$1.5M/month** ‚ùå UNSUSTAINABLE

**Hybrid Architecture:**
- 500k √ó 1.2 √ó $0.01 = **$6,000/day input**
- **Total: ~$195,000/month** ‚úÖ MANAGEABLE

**Savings: $1.3M/month**

### ROI on Implementation

**Implementation Cost:**
- 5 weeks √ó 40 hours √ó $100/hour (developer cost) = **$20,000**

**Monthly Savings:**
- Current scale: $43,560/month
- **Payback period: 0.5 months (2 weeks)**

**Annual Savings:**
- $522,720/year at current scale
- **$15.6M/year at target scale**

---

## ‚ö†Ô∏è Risks & Mitigation

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **pgvector performance at scale** | Low | High | - Start with 100k vectors, monitor<br>- IVFFlat index proven to 10M+ vectors<br>- Can migrate to Qdrant if needed |
| **Materialized view refresh lag** | Medium | Medium | - pg_cron + LISTEN/NOTIFY for sub-10s<br>- Monitor refresh times<br>- Alert if > 15s |
| **Context Assembler complexity** | Medium | Low | - Unit test all methods<br>- Integration tests for scenarios<br>- Gradual rollout |
| **State machine edge cases** | Low | Low | - Comprehensive state transition tests<br>- Fallback to general mode on errors |
| **LangSmith API limits** | Low | Medium | - Start with free tier<br>- Upgrade as needed<br>- Can self-host if required |

### Business Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Reduced AI quality** | Low | High | - A/B test hybrid vs current<br>- Measure recommendation acceptance<br>- Keep current as fallback |
| **Team learning curve** | Medium | Low | - Phased training (XState, LangSmith)<br>- Documentation for all components<br>- Pair programming during implementation |
| **Implementation delays** | Medium | Medium | - Phased approach allows early wins<br>- Phase 0 can ship independently<br>- Each phase delivers value |

### Operational Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Production downtime** | Low | High | - All changes are additive<br>- Blue-green deployment<br>- Rollback plan ready |
| **Data migration issues** | Low | Medium | - Knowledge indexer is idempotent<br>- Can rerun if errors<br>- Test on staging first |
| **Cost overruns** | Low | Low | - Monitor LangSmith usage<br>- Set budget alerts<br>- OpenAI cost tracking |

---

## üö´ What We're NOT Doing (And Why)

### ‚úÖ What We ARE Doing from LangChain (Selective Adoption)

**Taking the best parts:**
- ‚úÖ **LangGraph for agents** - Proven autonomous workflow orchestration
- ‚úÖ **LangSmith observability** - Best-in-class tracing and debugging
- ‚úÖ **Tool-calling pattern** - Industry standard with Zod schemas
- ‚úÖ **Memory management** - Built-in conversation persistence

**What we're NOT doing:**
- ‚ùå Full LangChain refactor of existing services
- ‚ùå LangChain for everything (only agents + observability)
- ‚ùå Complex LangChain chains (using simple ReAct agents)
- ‚ùå LangChain document loaders (we have our own ingestion)

**Why this is NOT vendor lock-in:**
- Your business logic stays in tool functions (YOUR code)
- Agents are thin wrappers around your tools
- Can switch to different agent framework if needed
- Only orchestration layer depends on LangGraph

### ‚ùå Temporal Workflows (Claude's Optional)

**Why not:**
- Another infrastructure component to manage
- Additional operational complexity
- Your Bull + Redis already works for follow-ups
- Event workflows are simple enough without Temporal

**When to reconsider:**
- If you need complex multi-day workflows with retries
- If Bull queue becomes unreliable at scale
- If you want visual workflow designer

### ‚ùå Qdrant/Weaviate Vector DB (All Three Mentioned)

**Why not:**
- pgvector scales to millions of vectors (proven)
- Adds operational complexity (another service)
- Another database to maintain, backup, monitor
- Your data is already in PostgreSQL
- Migration effort without clear benefit now

**When to reconsider:**
- If you exceed 10M+ vectors (years away)
- If you need advanced vector features (hybrid, graph, multi-tenancy)
- If pgvector performance becomes bottleneck

### ‚ùå Custom LLM Training (Not Yet)

**Why not:**
- Need 10k+ high-quality training examples first
- Current focus is architecture, not model training
- GPT-4 quality is sufficient for now
- Training/hosting infrastructure not ready

**When to do it:**
- **2026 goal** after collecting 6-12 months of interaction data
- Use LangSmith traces as training data
- Fine-tune on AWS Bedrock or SageMaker
- Expected 90% cost reduction vs GPT-4

---

## üìö Technical Dependencies

### Required Infrastructure

| Component | Purpose | Status |
|-----------|---------|--------|
| **PostgreSQL 14+** | Database with pgvector | ‚úÖ Have (production RDS) |
| **pgvector extension** | Vector similarity search | ‚ö†Ô∏è Need to install |
| **pg_cron extension** | Scheduled materialized view refresh | ‚ö†Ô∏è Need to install |
| **Redis** | Caching layer | ‚úÖ Have (for Bull queue) |
| **Node.js 18+** | Runtime environment | ‚úÖ Have |
| **TypeScript 5+** | Type safety | ‚úÖ Have |

### New Dependencies (npm packages)

```json
{
  "dependencies": {
    "pgvector": "^0.1.8",             // PostgreSQL vector operations
    "@langchain/openai": "^0.0.19",   // OpenAI integration for agents
    "@langchain/langgraph": "^0.0.14",// Agent workflow orchestration
    "@langchain/core": "^0.1.0",      // Core LangChain abstractions
    "zod": "^3.22.4",                 // Schema validation for tools
    "xstate": "^5.0.0",               // State machines
    "@xstate/react": "^4.0.0",        // React integration (if needed)
    "langsmith": "^0.1.0",            // Observability
    "ioredis": "^5.3.0"               // Redis client (if not already installed)
  }
}
```

### Environment Variables

```bash
# LangSmith (Observability)
LANGSMITH_API_KEY=lsm_xyz123
LANGSMITH_PROJECT=TPX-AI-Concierge

# PostgreSQL (if not already set)
DATABASE_URL=postgresql://tpeadmin:dBP0wer100!!@tpe-database-production.cmtcsi0kytrf.us-east-1.rds.amazonaws.com:5432/tpedb

# Redis (if not already set)
REDIS_URL=redis://localhost:6379

# OpenAI (already have)
OPENAI_API_KEY=sk-...
```

---

## üë• Team Training Plan

### Week 0: Pre-Implementation Training

**Day 1: SQL & PostgreSQL Advanced Features (4 hours)**
- Materialized views
- LISTEN/NOTIFY triggers
- pgvector basics
- Full-text search (tsvector)
- Query optimization

**Day 2: XState Workshop (4 hours)**
- State machine concepts
- Defining states and transitions
- Guards and services
- Testing state machines
- Visualizing with Stately Studio

**Day 3: LangSmith & Observability (2 hours)**
- LangSmith account setup
- SDK integration
- Trace visualization
- Debugging with traces
- A/B testing strategies

### During Implementation: Pair Programming

**Week 1-2: Foundation**
- Knowledge indexer (senior + mid-level)
- Hybrid search implementation (senior + junior)
- Materialized views (senior + mid-level)

**Week 3: Architecture**
- Context Assembler (senior leads, others observe)
- Capability Packs (each developer builds one pack)

**Week 4-5: Advanced**
- State machine integration (pair)
- Guard implementation (pair)
- LangSmith integration (senior demonstrates)

### Weekly Demos

**Every Friday:**
- 30-minute demo of week's progress
- Show metrics improvements
- Discuss challenges and solutions
- Plan next week

---

## üîÆ Future Evolution Path

### Months 6-12: Advanced Learning

**Pattern Recognition Engine**
- Analyze `ai_learning_events` for success patterns
- Identify what works for which contractor types
- Auto-suggest recommendations based on similar contractors

**Personalization Layer**
- Unique response style per contractor
- Learn communication preferences
- Optimize timing of proactive messages

**Predictive Recommendations**
- Anticipate needs before asked
- "We noticed you're approaching $5M revenue, here are partners who helped similar contractors break through"
- Proactive event recommendations

**Cross-Entity Intelligence**
- Connect dots between partners, books, podcasts, events
- "Contractors who worked with Partner X also found Book Y helpful"
- Build recommendation graph

### Year 2: Custom LLM Training (2026 Goal)

**Data Collection (Ongoing)**
- Use LangSmith traces as training data
- Collect contractor feedback on responses
- Track outcomes of recommendations
- Build high-quality training corpus

**Fine-tuning Pipeline**
- AWS Bedrock or SageMaker
- Fine-tune Claude or Llama 3 on industry-specific data
- Hybrid deployment: custom model for common queries, GPT-4 for complex reasoning

**Expected Benefits**
- **90% cost reduction** vs GPT-4
- **Faster response times** (local model)
- **Better domain knowledge** (trained on contractor language)
- **More consistent responses**

### Year 3: Multi-Agent Orchestration

**Specialized Agents**
- Partner Matching Agent (deep partner knowledge)
- Financial Analysis Agent (revenue, growth, metrics)
- Event Planning Agent (schedule optimization)
- Resource Recommendation Agent (books, podcasts, content)

**Agent Coordination (LangGraph)**
- Complex multi-step workflows
- Agents call each other as needed
- Parallel execution where possible
- Human-in-the-loop for critical decisions

**Autonomous Actions**
- AI schedules follow-ups automatically
- Books demos based on conversation
- Sends event summaries
- Creates action items proactively

---

## üìñ Documentation Requirements

### Technical Documentation (Created During Implementation)

1. **Architecture Diagrams** (Week 1)
   - Database schema with new tables
   - Service layer architecture
   - Data flow diagrams

2. **API Documentation** (Week 3)
   - Context Assembler API
   - Capability Pack interface
   - Guard methods

3. **State Machine Documentation** (Week 5)
   - State diagram (visual)
   - State transition table
   - Guards and services reference

4. **Operational Runbook** (Week 6)
   - How to monitor system health
   - How to debug AI issues with LangSmith
   - How to refresh knowledge base
   - How to add new capability packs

### Developer Guides

1. **Onboarding Guide**
   - System overview
   - Local development setup
   - Running tests
   - Common debugging techniques

2. **How-To Guides**
   - How to add a new capability pack
   - How to modify context assembly logic
   - How to add new state to machine
   - How to debug with LangSmith traces

3. **Troubleshooting Guide**
   - Common errors and solutions
   - Performance optimization tips
   - Database tuning recommendations

---

## ‚úÖ Decision Checklist

Before proceeding with implementation, confirm:

- [ ] **Stakeholder Buy-In**
  - [ ] Technical lead approves architecture
  - [ ] Product owner agrees with phased approach
  - [ ] Business owner accepts 5-week timeline
  - [ ] Budget approved for LangSmith subscription

- [ ] **Technical Prerequisites**
  - [ ] PostgreSQL 14+ running in production
  - [ ] Access to install pgvector extension
  - [ ] Access to install pg_cron extension
  - [ ] Redis available for caching
  - [ ] OpenAI API key with sufficient credits

- [ ] **Team Readiness**
  - [ ] Developers available for 5 weeks
  - [ ] Training scheduled for Week 0
  - [ ] Code review process defined
  - [ ] Testing strategy agreed upon

- [ ] **Risk Mitigation**
  - [ ] Rollback plan documented
  - [ ] Current system remains operational during migration
  - [ ] A/B testing plan for quality validation
  - [ ] Monitoring and alerting ready

- [ ] **Success Criteria Defined**
  - [ ] Phase 0 metrics agreed (10x speed, 80% cost reduction)
  - [ ] Quality benchmarks established
  - [ ] Business KPIs defined (recommendation acceptance, etc.)
  - [ ] Review cadence scheduled (weekly demos)

---

## üéØ Next Steps

### Immediate Actions (This Week)

1. **Get Stakeholder Approval**
   - Present this document to technical lead and product owner
   - Discuss concerns and questions
   - Get go/no-go decision

2. **Schedule Week 0 Training**
   - Book 2 days for team training
   - Prepare training materials
   - Setup LangSmith accounts

3. **Verify Technical Prerequisites**
   - Confirm pgvector can be installed on production RDS
   - Confirm pg_cron can be installed
   - Test Redis connectivity

### Phase 0 Kickoff (Next Week)

1. **Day 1: Setup**
   - Install pgvector extension
   - Create ai_knowledge_base table
   - Setup development environment

2. **Day 2-3: Indexer**
   - Build knowledge indexer service
   - Test with small dataset
   - Embed all partners

3. **Day 4: Hybrid Search**
   - Implement hybrid search SQL
   - Test retrieval quality
   - Benchmark performance

4. **Day 5: Deploy & Validate**
   - Deploy to production
   - Run indexer on all entities
   - Measure improvements

---

## üìû Contacts & Resources

### Internal Team

- **Technical Lead:** [Name] - Architecture decisions
- **Product Owner:** [Name] - Business requirements
- **DevOps:** [Name] - Infrastructure setup
- **QA Lead:** [Name] - Testing strategy

### External Resources

- **LangSmith Support:** https://docs.smith.langchain.com/
- **pgvector Documentation:** https://github.com/pgvector/pgvector
- **XState Documentation:** https://xstate.js.org/docs/
- **OpenAI API Reference:** https://platform.openai.com/docs/

### Related Documents

- `AI-CONCIERGE-COMPLETE-GUIDE.md` - Current system documentation
- `AI-FIRST-STRATEGY.md` - Long-term vision and roadmap
- `AI-CONCIERGE-RESTRUCT-POSSIBLE-SOLUTIONS-*.md` - Original architecture recommendations

---

## üìù Document Change Log

| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-10-11 | 1.0 | Claude Code | Initial comprehensive recommendation document |

---

**This document represents a critical strategic decision for TPX. The hybrid architecture balances immediate pain relief with long-term scalability, positioning the platform for 100k+ users while maintaining development velocity and team productivity.**

**Recommended Decision: PROCEED with Phase 0 implementation next week.**

# Phase 0: Hybrid Search & Knowledge Base Implementation Guide
## AI Concierge Restructure - Foundation

**Status:** Ready for Implementation
**Last Updated:** October 2025
**Database Verified:** âœ… All field names verified against production schema
**Aligned With:** [AI-CONCIERGE-HYBRID-ARCHITECTURE-RECOMMENDATION.md](AI-CONCIERGE-HYBRID-ARCHITECTURE-RECOMMENDATION.md) Phase 0

---

## ðŸŽ¯ Phase 0 Goals

**Primary Objective:** Replace monolithic loading of 1,443 columns with intelligent hybrid search returning top 12 relevant results.

**Success Metrics:**
- âš¡ Retrieval speed: < 200ms (from 2-3 seconds) = **10-15x faster**
- ðŸ’° API cost per request: < $0.02 (from ~$0.10) = **80% reduction**
- ðŸŽ¯ Context size: 12 items (from 1,443 columns) = **99% reduction**
- âœ… Independently testable retrieval quality

**Timeline:** Week 1 (5 days)

---

## ðŸ“‹ Pre-Implementation Database Verification

### âœ… VERIFIED: Existing Tables

#### 1. `entity_embeddings` Table (Already Exists)
**Verified via:** `quick-db.bat` query on October 2025

```sql
-- Current schema (8 columns):
id              INTEGER PRIMARY KEY
entity_type     VARCHAR(50) NOT NULL    -- 'partner', 'book', 'podcast', 'event'
entity_id       INTEGER NOT NULL
embedding_type  VARCHAR(50) NOT NULL    -- 'openai-ada-002', 'openai-3-small', etc.
embedding       ARRAY                   -- âš ï¸ Currently ARRAY, will migrate to vector
model_version   VARCHAR(50)
created_at      TIMESTAMP
updated_at      TIMESTAMP
```

**Status:** âš ï¸ Exists but uses ARRAY instead of pgvector type - **needs migration**

#### 2. Source Tables for Embeddings

**âœ… strategic_partners** - 21 AI fields verified:
- `id`, `company_name`, `focus_areas` (core fields)
- `ai_summary`, `ai_tags`, `ai_insights` (AI-processed fields)
- Total columns available: 123

**âœ… books** - 53 columns verified:
- `id`, `title`, `author`, `description` (core fields)
- `ai_summary`, `ai_tags`, `ai_insights` (AI-processed fields)
- `focus_areas_covered`, `topics`, `target_audience` (matching fields)

**âœ… podcasts** - 53 columns verified:
- `id`, `title`, `host`, `description` (core fields)
- `ai_summary`, `ai_tags` (AI-processed fields)
- `focus_areas_covered`, `topics`, `target_audience` (matching fields)

### âŒ NOT YET INSTALLED: pgvector Extension

```sql
-- Query result: 0 rows
SELECT * FROM pg_extension WHERE extname = 'vector';
```

**Action Required:** Install pgvector extension in Step 1

---

## ðŸ—ƒï¸ Database Schema Design (100% Verified Field Names)

### Option 1: Enhance Existing `entity_embeddings` Table â­ RECOMMENDED

**Why:** Table already exists, just needs pgvector migration and additional columns

```sql
-- Step 1: Install pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Step 2: Add new columns to existing table
ALTER TABLE entity_embeddings
  ADD COLUMN IF NOT EXISTS content TEXT,
  ADD COLUMN IF NOT EXISTS content_embedding vector(1536),  -- OpenAI ada-002 dimensions
  ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb,
  ADD COLUMN IF NOT EXISTS contractor_id INTEGER REFERENCES contractors(id);

-- Step 3: Migrate existing embeddings from ARRAY to vector
-- (This will be done via Node.js script to handle data transformation)

-- Step 4: Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_entity_embeddings_contractor
  ON entity_embeddings(contractor_id);

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_entity
  ON entity_embeddings(entity_type, entity_id);

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_vector
  ON entity_embeddings USING ivfflat (content_embedding vector_cosine_ops)
  WITH (lists = 100);  -- Adjust based on data size

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_content_fts
  ON entity_embeddings USING gin(to_tsvector('english', content));

-- Step 5: Add helpful comment
COMMENT ON TABLE entity_embeddings IS
  'Stores vector embeddings and content for hybrid search (BM25 + semantic).
   Supports both general knowledge (contractor_id IS NULL) and personalized (contractor_id NOT NULL).';
```

**Final Enhanced Schema:**
```sql
id                  INTEGER PRIMARY KEY
entity_type         VARCHAR(50) NOT NULL     -- 'partner', 'book', 'podcast', 'event'
entity_id           INTEGER NOT NULL
embedding_type      VARCHAR(50) NOT NULL     -- 'openai-ada-002', 'content', etc.
embedding           ARRAY                    -- Legacy field, keep for backward compatibility
model_version       VARCHAR(50)
content             TEXT                     -- NEW: Full-text content for BM25 search
content_embedding   vector(1536)            -- NEW: pgvector embedding for semantic search
metadata            JSONB                    -- NEW: Additional entity metadata
contractor_id       INTEGER                  -- NEW: NULL = general, NOT NULL = personalized
created_at          TIMESTAMP
updated_at          TIMESTAMP
```

### Option 2: Create New `ai_knowledge_base` Table (Alternative)

**Why:** Clean slate, matches hybrid architecture doc exactly

```sql
CREATE TABLE ai_knowledge_base (
  id SERIAL PRIMARY KEY,
  entity_type VARCHAR(50) NOT NULL,              -- 'partner', 'book', 'podcast', 'event'
  entity_id INTEGER NOT NULL,
  contractor_id INTEGER REFERENCES contractors(id),  -- NULL = general knowledge
  content TEXT NOT NULL,
  embedding vector(1536) NOT NULL,               -- OpenAI ada-002 embeddings
  metadata JSONB DEFAULT '{}'::jsonb,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_kb_contractor ON ai_knowledge_base(contractor_id);
CREATE INDEX idx_kb_entity ON ai_knowledge_base(entity_type, entity_id);
CREATE INDEX idx_kb_vector ON ai_knowledge_base USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
CREATE INDEX idx_kb_content_fts ON ai_knowledge_base USING gin(to_tsvector('english', content));
```

**Decision:** We'll use **Option 1** (enhance existing table) to avoid data migration complexity.

---

## ðŸ“ Implementation Steps

### Day 1: pgvector Setup & Table Enhancement

#### Step 1.1: Install pgvector Extension (LOCAL)

**File:** `tpe-database/migrations/001-install-pgvector.sql`

```sql
-- Install pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Verify installation
SELECT * FROM pg_extension WHERE extname = 'vector';

-- Test vector operations
SELECT '[1,2,3]'::vector <-> '[4,5,6]'::vector AS cosine_distance;
```

**Execute:**
```bash
# Local database
powershell -Command ".\quick-db.bat \"$(cat tpe-database/migrations/001-install-pgvector.sql)\""

# Verify
powershell -Command ".\quick-db.bat \"SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';\""
```

#### Step 1.2: Enhance `entity_embeddings` Table (LOCAL)

**File:** `tpe-database/migrations/002-enhance-entity-embeddings.sql`

```sql
-- Add new columns for hybrid search
ALTER TABLE entity_embeddings
  ADD COLUMN IF NOT EXISTS content TEXT,
  ADD COLUMN IF NOT EXISTS content_embedding vector(1536),
  ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}'::jsonb,
  ADD COLUMN IF NOT EXISTS contractor_id INTEGER REFERENCES contractors(id);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_entity_embeddings_contractor
  ON entity_embeddings(contractor_id);

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_entity
  ON entity_embeddings(entity_type, entity_id);

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_vector
  ON entity_embeddings USING ivfflat (content_embedding vector_cosine_ops)
  WITH (lists = 100);

CREATE INDEX IF NOT EXISTS idx_entity_embeddings_content_fts
  ON entity_embeddings USING gin(to_tsvector('english', content));

-- Add table comment
COMMENT ON TABLE entity_embeddings IS
  'Enhanced with hybrid search: BM25 (full-text) + vector (semantic). Supports personalized and general knowledge.';

-- Verify new structure
SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'entity_embeddings'
ORDER BY ordinal_position;
```

**Execute:**
```bash
powershell -Command ".\quick-db.bat \"$(cat tpe-database/migrations/002-enhance-entity-embeddings.sql)\""
```

#### Step 1.3: Create Migration Scripts for Production

**Note:** Production will use the same SQL files but executed via AWS RDS console or migration tool.

---

### Day 2-3: Knowledge Indexer Service

#### Step 2.1: Build Content Assembler

**File:** `tpe-backend/src/services/knowledgeContentAssembler.js`

```javascript
/**
 * Assembles searchable content from entities for embedding
 * Uses VERIFIED database field names
 */
class KnowledgeContentAssembler {

  /**
   * Build content string for a strategic partner
   * VERIFIED FIELDS: company_name, ai_summary, ai_tags, focus_areas, ai_insights
   */
  async assemblePartnerContent(partnerId) {
    const result = await db.query(`
      SELECT
        id,
        company_name,
        ai_summary,
        ai_tags,
        focus_areas,
        ai_insights,
        ai_generated_differentiators
      FROM strategic_partners
      WHERE id = $1
    `, [partnerId]);

    if (result.rows.length === 0) return null;

    const partner = result.rows[0];

    // Build searchable content
    const content = `
${partner.company_name}

Summary: ${partner.ai_summary || 'No summary available'}

Focus Areas: ${Array.isArray(partner.focus_areas) ? partner.focus_areas.join(', ') : 'None'}

Differentiators: ${partner.ai_generated_differentiators || 'None'}

Tags: ${Array.isArray(partner.ai_tags) ? partner.ai_tags.join(', ') : 'None'}

Insights: ${partner.ai_insights || 'None'}
    `.trim();

    // Build metadata
    const metadata = {
      company_name: partner.company_name,
      focus_areas: partner.focus_areas || [],
      tags: partner.ai_tags || [],
      has_summary: !!partner.ai_summary
    };

    return { content, metadata };
  }

  /**
   * Build content string for a book
   * VERIFIED FIELDS: title, author, ai_summary, ai_tags, focus_areas_covered, description
   */
  async assembleBookContent(bookId) {
    const result = await db.query(`
      SELECT
        id,
        title,
        author,
        description,
        ai_summary,
        ai_tags,
        focus_areas_covered,
        topics,
        key_takeaways
      FROM books
      WHERE id = $1
    `, [bookId]);

    if (result.rows.length === 0) return null;

    const book = result.rows[0];

    const content = `
${book.title} by ${book.author}

Summary: ${book.ai_summary || book.description || 'No summary available'}

Focus Areas: ${Array.isArray(book.focus_areas_covered) ? book.focus_areas_covered.join(', ') : 'None'}

Topics: ${Array.isArray(book.topics) ? book.topics.join(', ') : 'None'}

Key Takeaways: ${Array.isArray(book.key_takeaways) ? book.key_takeaways.join('; ') : 'None'}

Tags: ${Array.isArray(book.ai_tags) ? book.ai_tags.join(', ') : 'None'}
    `.trim();

    const metadata = {
      title: book.title,
      author: book.author,
      focus_areas: book.focus_areas_covered || [],
      topics: book.topics || [],
      tags: book.ai_tags || []
    };

    return { content, metadata };
  }

  /**
   * Build content string for a podcast
   * VERIFIED FIELDS: title, host, ai_summary, ai_tags, focus_areas_covered, description
   */
  async assemblePodcastContent(podcastId) {
    const result = await db.query(`
      SELECT
        id,
        title,
        host,
        description,
        ai_summary,
        ai_tags,
        focus_areas_covered,
        topics,
        notable_guests
      FROM podcasts
      WHERE id = $1
    `, [podcastId]);

    if (result.rows.length === 0) return null;

    const podcast = result.rows[0];

    const content = `
${podcast.title} hosted by ${podcast.host}

Summary: ${podcast.ai_summary || podcast.description || 'No summary available'}

Focus Areas: ${Array.isArray(podcast.focus_areas_covered) ? podcast.focus_areas_covered.join(', ') : 'None'}

Topics: ${Array.isArray(podcast.topics) ? podcast.topics.join(', ') : 'None'}

Notable Guests: ${Array.isArray(podcast.notable_guests) ? podcast.notable_guests.join(', ') : 'None'}

Tags: ${Array.isArray(podcast.ai_tags) ? podcast.ai_tags.join(', ') : 'None'}
    `.trim();

    const metadata = {
      title: podcast.title,
      host: podcast.host,
      focus_areas: podcast.focus_areas_covered || [],
      topics: podcast.topics || [],
      tags: podcast.ai_tags || []
    };

    return { content, metadata };
  }
}

module.exports = new KnowledgeContentAssembler();
```

#### Step 2.2: Build Embedding Service

**File:** `tpe-backend/src/services/embeddingService.js`

```javascript
const OpenAI = require('openai');
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

/**
 * Generates OpenAI embeddings for content
 */
class EmbeddingService {

  /**
   * Generate embedding for text content
   * @param {string} content - Text to embed
   * @returns {Promise<number[]>} - 1536-dimensional vector
   */
  async generateEmbedding(content) {
    if (!content || content.trim().length === 0) {
      throw new Error('Content cannot be empty');
    }

    try {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: content,
        encoding_format: 'float'
      });

      return response.data[0].embedding;
    } catch (error) {
      console.error('[EmbeddingService] Error generating embedding:', error);
      throw error;
    }
  }

  /**
   * Generate embeddings in batch
   * @param {string[]} contents - Array of texts to embed
   * @returns {Promise<number[][]>} - Array of embeddings
   */
  async generateEmbeddingsBatch(contents) {
    if (!contents || contents.length === 0) {
      return [];
    }

    try {
      const response = await openai.embeddings.create({
        model: 'text-embedding-ada-002',
        input: contents,
        encoding_format: 'float'
      });

      return response.data.map(item => item.embedding);
    } catch (error) {
      console.error('[EmbeddingService] Error generating batch embeddings:', error);
      throw error;
    }
  }
}

module.exports = new EmbeddingService();
```

#### Step 2.3: Build Knowledge Indexer

**File:** `tpe-backend/src/services/knowledgeIndexer.js`

```javascript
const { query } = require('../config/database');
const contentAssembler = require('./knowledgeContentAssembler');
const embeddingService = require('./embeddingService');

/**
 * Indexes entities into entity_embeddings table with hybrid search support
 * VERIFIED TABLE: entity_embeddings with content, content_embedding, metadata fields
 */
class KnowledgeIndexer {

  /**
   * Index a single entity
   * @param {string} entityType - 'partner', 'book', 'podcast', 'event'
   * @param {number} entityId - Entity ID
   * @param {number|null} contractorId - NULL for general, ID for personalized
   */
  async indexEntity(entityType, entityId, contractorId = null) {
    console.log(`[KnowledgeIndexer] Indexing ${entityType} ${entityId}...`);

    // Step 1: Assemble content
    let assembledData;
    switch (entityType) {
      case 'partner':
        assembledData = await contentAssembler.assemblePartnerContent(entityId);
        break;
      case 'book':
        assembledData = await contentAssembler.assembleBookContent(entityId);
        break;
      case 'podcast':
        assembledData = await contentAssembler.assemblePodcastContent(entityId);
        break;
      default:
        throw new Error(`Unknown entity type: ${entityType}`);
    }

    if (!assembledData) {
      console.warn(`[KnowledgeIndexer] No data found for ${entityType} ${entityId}`);
      return null;
    }

    const { content, metadata } = assembledData;

    // Step 2: Generate embedding
    const embedding = await embeddingService.generateEmbedding(content);

    // Step 3: Upsert to entity_embeddings table
    // VERIFIED FIELDS: entity_type, entity_id, embedding_type, content, content_embedding, metadata, contractor_id
    const result = await query(`
      INSERT INTO entity_embeddings
        (entity_type, entity_id, embedding_type, content, content_embedding, metadata, contractor_id, created_at, updated_at)
      VALUES ($1, $2, $3, $4, $5::vector, $6::jsonb, $7, NOW(), NOW())
      ON CONFLICT (entity_type, entity_id, contractor_id)
      DO UPDATE SET
        content = EXCLUDED.content,
        content_embedding = EXCLUDED.content_embedding,
        metadata = EXCLUDED.metadata,
        updated_at = NOW()
      RETURNING id
    `, [
      entityType,
      entityId,
      'content',  // embedding_type
      content,
      `[${embedding.join(',')}]`,  // Convert array to pgvector format
      JSON.stringify(metadata),
      contractorId
    ]);

    console.log(`[KnowledgeIndexer] Indexed ${entityType} ${entityId} -> embedding ID ${result.rows[0].id}`);
    return result.rows[0].id;
  }

  /**
   * Index all partners
   */
  async indexAllPartners() {
    console.log('[KnowledgeIndexer] Starting partner indexing...');

    const partners = await query('SELECT id FROM strategic_partners WHERE is_active = true');
    const total = partners.rows.length;
    let indexed = 0;

    for (const partner of partners.rows) {
      try {
        await this.indexEntity('partner', partner.id);
        indexed++;
        console.log(`[KnowledgeIndexer] Progress: ${indexed}/${total} partners`);
      } catch (error) {
        console.error(`[KnowledgeIndexer] Failed to index partner ${partner.id}:`, error);
      }
    }

    console.log(`[KnowledgeIndexer] Partner indexing complete: ${indexed}/${total}`);
    return { total, indexed };
  }

  /**
   * Index all books
   */
  async indexAllBooks() {
    console.log('[KnowledgeIndexer] Starting book indexing...');

    const books = await query('SELECT id FROM books WHERE is_active = true');
    const total = books.rows.length;
    let indexed = 0;

    for (const book of books.rows) {
      try {
        await this.indexEntity('book', book.id);
        indexed++;
        console.log(`[KnowledgeIndexer] Progress: ${indexed}/${total} books`);
      } catch (error) {
        console.error(`[KnowledgeIndexer] Failed to index book ${book.id}:`, error);
      }
    }

    console.log(`[KnowledgeIndexer] Book indexing complete: ${indexed}/${total}`);
    return { total, indexed };
  }

  /**
   * Index all podcasts
   */
  async indexAllPodcasts() {
    console.log('[KnowledgeIndexer] Starting podcast indexing...');

    const podcasts = await query('SELECT id FROM podcasts WHERE is_active = true');
    const total = podcasts.rows.length;
    let indexed = 0;

    for (const podcast of podcasts.rows) {
      try {
        await this.indexEntity('podcast', podcast.id);
        indexed++;
        console.log(`[KnowledgeIndexer] Progress: ${indexed}/${total} podcasts`);
      } catch (error) {
        console.error(`[KnowledgeIndexer] Failed to index podcast ${podcast.id}:`, error);
      }
    }

    console.log(`[KnowledgeIndexer] Podcast indexing complete: ${indexed}/${total}`);
    return { total, indexed };
  }

  /**
   * Index all entities
   */
  async indexAll() {
    console.log('[KnowledgeIndexer] Starting full knowledge base indexing...');
    const start = Date.now();

    const results = {
      partners: await this.indexAllPartners(),
      books: await this.indexAllBooks(),
      podcasts: await this.indexAllPodcasts()
    };

    const elapsed = Date.now() - start;
    console.log(`[KnowledgeIndexer] Full indexing complete in ${elapsed}ms`);
    console.log('[KnowledgeIndexer] Results:', results);

    return results;
  }
}

module.exports = new KnowledgeIndexer();
```

---

### Day 4: Hybrid Search Implementation

#### Step 4.1: Build Hybrid Search Service

**File:** `tpe-backend/src/services/hybridSearchService.js`

```javascript
const { query } = require('../config/database');
const embeddingService = require('./embeddingService');

/**
 * Hybrid search: BM25 (keyword) + Vector (semantic)
 * Queries VERIFIED TABLE: entity_embeddings with content, content_embedding fields
 */
class HybridSearchService {

  /**
   * Perform hybrid search
   * @param {string} queryText - User's search query
   * @param {number|null} contractorId - Contractor ID for personalization (NULL = general)
   * @param {number} limit - Number of results to return (default 12)
   * @param {string[]} entityTypes - Filter by entity types (default all)
   * @returns {Promise<Array>} - Top results with hybrid scores
   */
  async search(queryText, contractorId = null, limit = 12, entityTypes = null) {
    console.log(`[HybridSearch] Query: "${queryText}", Contractor: ${contractorId}, Limit: ${limit}`);

    // Step 1: Generate query embedding
    const queryEmbedding = await embeddingService.generateEmbedding(queryText);

    // Step 2: Execute hybrid search SQL
    // VERIFIED FIELDS: entity_type, entity_id, content, content_embedding, metadata, contractor_id
    const searchQuery = `
      WITH bm25_results AS (
        SELECT
          id,
          entity_type,
          entity_id,
          content,
          metadata,
          ts_rank(
            to_tsvector('english', content),
            plainto_tsquery('english', $1)
          ) AS bm25_score
        FROM entity_embeddings
        WHERE (contractor_id = $2 OR contractor_id IS NULL)
          ${entityTypes ? 'AND entity_type = ANY($4)' : ''}
      ),
      vector_results AS (
        SELECT
          id,
          entity_type,
          entity_id,
          1 - (content_embedding <=> $3::vector) AS vector_score
        FROM entity_embeddings
        WHERE (contractor_id = $2 OR contractor_id IS NULL)
          ${entityTypes ? 'AND entity_type = ANY($4)' : ''}
      )
      SELECT
        ee.*,
        COALESCE(bm25.bm25_score, 0) AS bm25_score,
        COALESCE(vs.vector_score, 0) AS vector_score,
        (0.4 * COALESCE(bm25.bm25_score, 0) + 0.6 * COALESCE(vs.vector_score, 0)) AS hybrid_score
      FROM entity_embeddings ee
      LEFT JOIN bm25_results bm25 USING(id)
      LEFT JOIN vector_results vs USING(id)
      WHERE (ee.contractor_id = $2 OR ee.contractor_id IS NULL)
        ${entityTypes ? 'AND ee.entity_type = ANY($4)' : ''}
      ORDER BY hybrid_score DESC
      LIMIT $${entityTypes ? 5 : 4}
    `;

    const params = [
      queryText,
      contractorId,
      `[${queryEmbedding.join(',')}]`,
      entityTypes,
      limit
    ].filter(p => p !== null);

    const result = await query(searchQuery, params);

    console.log(`[HybridSearch] Found ${result.rows.length} results`);

    return result.rows.map(row => ({
      id: row.id,
      entity_type: row.entity_type,
      entity_id: row.entity_id,
      content: row.content,
      metadata: row.metadata,
      scores: {
        bm25: parseFloat(row.bm25_score),
        vector: parseFloat(row.vector_score),
        hybrid: parseFloat(row.hybrid_score)
      }
    }));
  }

  /**
   * Search only partners
   */
  async searchPartners(queryText, contractorId = null, limit = 5) {
    return this.search(queryText, contractorId, limit, ['partner']);
  }

  /**
   * Search only books
   */
  async searchBooks(queryText, contractorId = null, limit = 5) {
    return this.search(queryText, contractorId, limit, ['book']);
  }

  /**
   * Search only podcasts
   */
  async searchPodcasts(queryText, contractorId = null, limit = 5) {
    return this.search(queryText, contractorId, limit, ['podcast']);
  }
}

module.exports = new HybridSearchService();
```

---

### Day 5: Testing & Validation

#### Step 5.1: Create Test Script

**File:** `tpe-backend/test-hybrid-search.js`

```javascript
const knowledgeIndexer = require('./src/services/knowledgeIndexer');
const hybridSearchService = require('./src/services/hybridSearchService');

async function testHybridSearch() {
  console.log('=== Hybrid Search Test ===\n');

  // Test 1: Index a few entities
  console.log('1. Indexing sample entities...');
  await knowledgeIndexer.indexEntity('partner', 1);
  await knowledgeIndexer.indexEntity('book', 1);
  await knowledgeIndexer.indexEntity('podcast', 1);
  console.log('âœ“ Indexing complete\n');

  // Test 2: Search for partners
  console.log('2. Testing partner search...');
  const partnerResults = await hybridSearchService.searchPartners('lead generation CRM');
  console.log(`Found ${partnerResults.length} partners`);
  console.log('Top result:', partnerResults[0]);
  console.log('âœ“ Partner search working\n');

  // Test 3: General search
  console.log('3. Testing general search...');
  const generalResults = await hybridSearchService.search('business growth strategies', null, 12);
  console.log(`Found ${generalResults.length} total results`);
  console.log('Top 3 entity types:', generalResults.slice(0, 3).map(r => r.entity_type));
  console.log('âœ“ General search working\n');

  // Test 4: Performance benchmark
  console.log('4. Performance benchmark...');
  const start = Date.now();
  await hybridSearchService.search('contractor business advice', null, 12);
  const elapsed = Date.now() - start;
  console.log(`Search completed in ${elapsed}ms`);
  console.log(elapsed < 200 ? 'âœ“ Performance target met (<200ms)' : 'âš ï¸ Performance needs optimization');

  console.log('\n=== Test Complete ===');
  process.exit(0);
}

testHybridSearch().catch(error => {
  console.error('Test failed:', error);
  process.exit(1);
});
```

**Run test:**
```bash
node tpe-backend/test-hybrid-search.js
```

#### Step 5.2: Integration with AI Concierge

**Modify:** `tpe-backend/src/services/aiKnowledgeService.js`

```javascript
const hybridSearchService = require('./hybridSearchService');

class AIKnowledgeService {

  /**
   * Get comprehensive knowledge using hybrid search
   * REPLACES: Old getDynamicKnowledge() that loaded 1,443 columns
   */
  async getComprehensiveKnowledge(contractorId, userQuery = '') {
    console.log(`[AIKnowledgeService] Getting knowledge for contractor ${contractorId}`);

    // Use hybrid search instead of loading all tables
    const searchResults = await hybridSearchService.search(
      userQuery || 'business growth contractor advice',  // Default query if none provided
      contractorId,
      12  // Top 12 results
    );

    // Group results by entity type
    const knowledge = {
      partners: { data: [], count: 0 },
      books: { data: [], count: 0 },
      podcasts: { data: [], count: 0 },
      totalResults: searchResults.length
    };

    for (const result of searchResults) {
      const item = {
        id: result.entity_id,
        ...result.metadata,
        relevance_score: result.scores.hybrid,
        snippet: result.content.substring(0, 300) + '...'
      };

      if (result.entity_type === 'partner') {
        knowledge.partners.data.push(item);
        knowledge.partners.count++;
      } else if (result.entity_type === 'book') {
        knowledge.books.data.push(item);
        knowledge.books.count++;
      } else if (result.entity_type === 'podcast') {
        knowledge.podcasts.data.push(item);
        knowledge.podcasts.count++;
      }
    }

    console.log(`[AIKnowledgeService] Retrieved ${searchResults.length} items via hybrid search`);
    return knowledge;
  }

  // Keep existing methods for backward compatibility
  // ...existing code...
}

module.exports = new AIKnowledgeService();
```

---

## ðŸ§ª Validation Checklist

### Database Verification
- [ ] pgvector extension installed locally
- [ ] `entity_embeddings` table enhanced with new columns
- [ ] All indexes created successfully
- [ ] Sample query with vector operations works

### Indexing Verification
- [ ] Content assembler generates proper content for partners
- [ ] Content assembler generates proper content for books
- [ ] Content assembler generates proper content for podcasts
- [ ] Embeddings generated successfully
- [ ] Upserts to entity_embeddings work correctly

### Search Verification
- [ ] BM25 (full-text) search returns results
- [ ] Vector (semantic) search returns results
- [ ] Hybrid scoring combines both correctly
- [ ] Results sorted by hybrid_score DESC
- [ ] Personalized search (contractor_id) works
- [ ] General search (contractor_id NULL) works

### Performance Verification
- [ ] Search completes in < 200ms âœ… **10x faster than 2-3s**
- [ ] Returns exactly 12 results (configurable)
- [ ] No performance degradation with concurrent requests

### Integration Verification
- [ ] AI Concierge uses hybrid search instead of old method
- [ ] Context size reduced to 12 items âœ… **99% reduction**
- [ ] AI responses still accurate with smaller context

---

## ðŸ“Š Success Metrics - Expected Results

**Before Phase 0:**
- Retrieval time: 2-3 seconds
- Context size: 1,443 columns
- API cost per request: ~$0.10
- Testability: Cannot test retrieval independently

**After Phase 0:**
- Retrieval time: **< 200ms** âœ… 10-15x faster
- Context size: **12 items** âœ… 99% reduction
- API cost per request: **< $0.02** âœ… 80% reduction
- Testability: **Full unit test coverage** âœ…

---

## ðŸš€ Deployment Process

### Local Deployment
```bash
# 1. Run database migrations
powershell -Command ".\quick-db.bat \"$(cat tpe-database/migrations/001-install-pgvector.sql)\""
powershell -Command ".\quick-db.bat \"$(cat tpe-database/migrations/002-enhance-entity-embeddings.sql)\""

# 2. Verify schema
powershell -Command ".\quick-db.bat \"SELECT column_name FROM information_schema.columns WHERE table_name = 'entity_embeddings' ORDER BY ordinal_position;\""

# 3. Run initial indexing
node tpe-backend/scripts/index-knowledge-base.js

# 4. Test hybrid search
node tpe-backend/test-hybrid-search.js

# 5. Restart backend with hybrid search enabled
node dev-manager.js restart backend
```

### Production Deployment
```bash
# 1. Install pgvector on AWS RDS (via AWS Console or CLI)
# 2. Run migrations on production database
# 3. Run indexing job
# 4. Monitor performance
# 5. Enable in production (feature flag)
```

---

## ðŸ”§ Troubleshooting

### Issue: pgvector extension won't install
**Solution:** Ensure PostgreSQL 14+ with vector extension support. On AWS RDS, may need to enable via parameter group.

### Issue: Embedding generation slow
**Solution:** Use batch embedding generation for multiple entities. Consider rate limiting.

### Issue: Search returns no results
**Solution:** Check if entities are indexed. Verify content is not NULL. Check vector dimensions match (1536).

### Issue: Performance < 200ms target
**Solution:**
- Check index usage with EXPLAIN ANALYZE
- Adjust IVFFlat lists parameter
- Ensure content_embedding column is indexed
- Consider warming cache

---

## ðŸ“ Next Steps

After Phase 0 completion:
1. **Phase 1:** Event Truth Management (materialized views)
2. **Phase 2:** LangGraph Agent Migration
3. **Phase 3:** Observability & Guardrails
4. **Phase 4:** State Machine Integration
5. **Phase 5:** Production Optimization

**Phase 0 Status:** Ready for implementation - all database fields verified âœ…

---

**Document Created:** October 2025
**Database Verification:** âœ… Complete
**Ready for Implementation:** YES
